{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "(Oct.18) Lesson 1 - Datatypes Tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YasPHP/LearnAI/blob/main/(Oct_18)_Lesson_1_Datatypes_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jbu1Z5-BlNfV"
      },
      "source": [
        "# Google Colab\n",
        "Google Colab allows people to write and execute python code in-browser in sections as well as make formatted comments. This is invaluable when working with others and keeping your code accessible. It is perfect for the purposes of this course, and we highly encourage you to use it as well!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzDZGlhIvmBz"
      },
      "source": [
        "Some things to know:\n",
        "\n",
        "Cells - In Google Colab, cells are chunks of code or text.\n",
        "\n",
        "Running a Cell - A code cell can be run by hovering over the cell brackets and clicking the Play button.\n",
        "\n",
        "Output - The three ways to get output in Colab are as following: using a print statement; plotting something; or if the final line of a code cell is a variable with no assignment, Colab will print that variable.\n",
        "\n",
        "Deleting Output - You can print output which appears below the cell. To delete this output, hover over the icon on the left side and click the X button. Things may be printed to output without using the actual print function.\n",
        "\n",
        "Showing Hidden Solution Sections - These tutorials will always have hidden solution sections. To show these sections, click on the **SHOW CODE** text or double click on the cell. Only do this after trying to solve it yourself (and trying to debug).\n",
        "\n",
        "Try unhiding the cell directly below, running it, and clearing the output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "csHcT4yHP51G"
      },
      "source": [
        "#@title\n",
        "string = \"Hello World\"\n",
        "print(string + ' (using print function)')\n",
        "string + ' (without print function)'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XgREugrRa6o"
      },
      "source": [
        "# Loading Data into Google Colab\n",
        "The three simplest ways to load data into Google Colab are as follows:\n",
        "1. Find data which is available online through a link, e.g.\n",
        "https://gist.githubusercontent.com/netj/8836201/raw/6f9306ad21398ea43cba4f7d537619d0e07d5ae3/iris.csv\n",
        "These can be easily loaded in by many libaries, such as Pandas. Obviously, this is mostly just useful for testing purposes, unless the data you need is available online. For this course, we have made all the necessary data into links to avoid any hassle and avoid wasting time.\n",
        "\n",
        "2. Load the data in through various libraries. Many libaries, such as Keras, give you access to different sorts of datasets, which could even save you valuable time doing pre-processing, e.g.\n",
        "```\n",
        "from keras.datasets import mnist\n",
        "mnist.load_data()\n",
        "```\n",
        "\n",
        "3. Finally, you will need to create or gather custom data yourself. The easiest way to save it to, and load it from Google Drive, e.g.\n",
        "```\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/path/to/data/in/drive')\n",
        "```\n",
        "From here you are given an authorization link and a code prompt. Click the link, log into your account, and copy/paste the access code into the prompt. Now you can click on the 'Files' icon on the left sidebar of Google Colab, copy the path of your data, and load said data from there.\n",
        "```\n",
        "import pandas as pd\n",
        "df=pd.read_csv('in/files/data.csv')\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VV-1NPwf0Ma"
      },
      "source": [
        "# Datatypes\n",
        "The following datatypes are used to bring stored data from outside sources & files into your Python scripts for use. Some are more useful for data preparation, something you'll find you need to do before performing any ML.\n",
        "\n",
        "We'll also introduce you to two libaries which encapsulate these datatypes: Pandas and Numpy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_uq3T5NgG1II"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jlkOHVkfLlv"
      },
      "source": [
        "# Pandas Dataframes\n",
        "Dataframes are Pandas data structures which function similar to how CSVs look, with columns and rows. CSVs are commonly loaded into these dataframes, although they support many file types. Pandas is generally used for data manipulation and preparation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LHzEkG2fdmAd",
        "outputId": "f06378b9-fe44-44c6-b11f-82eb6e46e08c"
      },
      "source": [
        "df = pd.read_csv(\"https://gist.githubusercontent.com/netj/8836201/raw/6f9306ad21398ea43cba4f7d537619d0e07d5ae3/iris.csv\")\n",
        "print(df.head())\n",
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   sepal.length  sepal.width  petal.length  petal.width variety\n",
            "0           5.1          3.5           1.4          0.2  Setosa\n",
            "1           4.9          3.0           1.4          0.2  Setosa\n",
            "2           4.7          3.2           1.3          0.2  Setosa\n",
            "3           4.6          3.1           1.5          0.2  Setosa\n",
            "4           5.0          3.6           1.4          0.2  Setosa\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal.length</th>\n",
              "      <th>sepal.width</th>\n",
              "      <th>petal.length</th>\n",
              "      <th>petal.width</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>150.000000</td>\n",
              "      <td>150.000000</td>\n",
              "      <td>150.000000</td>\n",
              "      <td>150.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>5.843333</td>\n",
              "      <td>3.057333</td>\n",
              "      <td>3.758000</td>\n",
              "      <td>1.199333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.828066</td>\n",
              "      <td>0.435866</td>\n",
              "      <td>1.765298</td>\n",
              "      <td>0.762238</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>4.300000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>5.100000</td>\n",
              "      <td>2.800000</td>\n",
              "      <td>1.600000</td>\n",
              "      <td>0.300000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>5.800000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.350000</td>\n",
              "      <td>1.300000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.400000</td>\n",
              "      <td>3.300000</td>\n",
              "      <td>5.100000</td>\n",
              "      <td>1.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>7.900000</td>\n",
              "      <td>4.400000</td>\n",
              "      <td>6.900000</td>\n",
              "      <td>2.500000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       sepal.length  sepal.width  petal.length  petal.width\n",
              "count    150.000000   150.000000    150.000000   150.000000\n",
              "mean       5.843333     3.057333      3.758000     1.199333\n",
              "std        0.828066     0.435866      1.765298     0.762238\n",
              "min        4.300000     2.000000      1.000000     0.100000\n",
              "25%        5.100000     2.800000      1.600000     0.300000\n",
              "50%        5.800000     3.000000      4.350000     1.300000\n",
              "75%        6.400000     3.300000      5.100000     1.800000\n",
              "max        7.900000     4.400000      6.900000     2.500000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kpFzgGcUP7y"
      },
      "source": [
        "Do NOT ignore Pandas' many, many built-in functions that can help you re-shape your data! They're probably a Google search away!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "UD_aODR4UXvm",
        "outputId": "3d225c27-a669-4a79-96cc-78933c59d284"
      },
      "source": [
        "# Create a copy of the df loaded above (So we won't have to reload it)\n",
        "df_copy = df.copy()\n",
        "\n",
        "# Mask data (Which is to remove data which doesn't satisfy the mask's conditions)\n",
        "petal_length_mask = ((df_copy['petal.length'] >= 1.5) & (df_copy['petal.length'] < 2))\n",
        "df_copy = df_copy[petal_length_mask]\n",
        "print(df_copy.head())\n",
        "\n",
        "# Re-shape index after mask\n",
        "df_copy.reset_index(drop=True, inplace=True)\n",
        "print(df_copy.head())\n",
        "\n",
        "# Convert length measurements from centimeters to meters\n",
        "cols = ['sepal.length', 'sepal.width', 'petal.length', 'petal.width']\n",
        "df_copy[cols] = df_copy[cols].applymap(lambda s: s/100)\n",
        "print(df_copy.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    sepal.length  sepal.width  petal.length  petal.width variety\n",
            "3            4.6          3.1           1.5          0.2  Setosa\n",
            "5            5.4          3.9           1.7          0.4  Setosa\n",
            "7            5.0          3.4           1.5          0.2  Setosa\n",
            "9            4.9          3.1           1.5          0.1  Setosa\n",
            "10           5.4          3.7           1.5          0.2  Setosa\n",
            "   sepal.length  sepal.width  petal.length  petal.width variety\n",
            "0           4.6          3.1           1.5          0.2  Setosa\n",
            "1           5.4          3.9           1.7          0.4  Setosa\n",
            "2           5.0          3.4           1.5          0.2  Setosa\n",
            "3           4.9          3.1           1.5          0.1  Setosa\n",
            "4           5.4          3.7           1.5          0.2  Setosa\n",
            "   sepal.length  sepal.width  petal.length  petal.width variety\n",
            "0         0.046        0.031         0.015        0.002  Setosa\n",
            "1         0.054        0.039         0.017        0.004  Setosa\n",
            "2         0.050        0.034         0.015        0.002  Setosa\n",
            "3         0.049        0.031         0.015        0.001  Setosa\n",
            "4         0.054        0.037         0.015        0.002  Setosa\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTp5Fmi7a61L"
      },
      "source": [
        "# Exercise Practice\n",
        "Try to perform the following 3 operations on the data using built-in Pandas functions:\n",
        "1. Create a mask which limits sepal width between 3.0 and 3.6 inclusive.\n",
        "2. Drop the 'variety' column.\n",
        "3. Calculate the mean sepal length and drop sepal values below that mean.\n",
        "\n",
        "Now, there is hidden solution code if you get stuck, but do not open it until you've looked up some functions and tried them! You may even come up with a completely different solution. Use *.head()* and *.describe()* to verify your results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXxl8_Hee5PL"
      },
      "source": [
        "# Creates a copy of the df loaded above (So we won't have to reload it)\n",
        "df_copy = df.copy()\n",
        "\n",
        "# TODO - sepal_width_mask ((df_copy['petal.width'] >= 3.0) & (df_copy['petal.width'] <= 3.6))\n",
        "\n",
        "# TODO - 2\n",
        "\n",
        "# TODO - 3\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGsumGbxdBlO"
      },
      "source": [
        "#@title\n",
        "# Create a copy of the df loaded above (So we won't have to reload it)\n",
        "df_copy = df.copy()\n",
        "\n",
        "# 1\n",
        "sepal_width_mask = ((df_copy['sepal.width'] >= 3.0) & (df_copy['sepal.width'] <= 3.6))\n",
        "df_copy = df_copy[sepal_width_mask]\n",
        "print(df_copy.head())\n",
        "\n",
        "# 2\n",
        "df_copy.drop('variety', axis=1, inplace=True)\n",
        "# Or you could use this notation\n",
        "#del df_copy['variety']\n",
        "print(df_copy.head())\n",
        "print(df_copy.describe())\n",
        "\n",
        "# 3\n",
        "sepal_length_mean_mask = (df_copy[\"sepal.length\"] < df_copy[\"sepal.length\"].mean())\n",
        "df_copy = df_copy[sepal_length_mean_mask]\n",
        "print(df_copy.describe())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IS62gv2glYo"
      },
      "source": [
        "# Numpy Arrays\n",
        "Numpy Arrays are data structures that, on the surface, act similarly to Python lists. However, they have much more complexity because they can handle different dimensions of data, support many built-in functions that help you re-structure and shape your data, are used by many other libraries, and also perform operations much more quickly than native Python operations. We will be using these arrays mostly as inputs to ML models through Tensorflow's Keras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "id": "aLn5RZgWhRuR"
      },
      "source": [
        "lst = [[1, 3, 5], [2, 4, 7], [9, 8, 6]]\n",
        "array = np.asarray(lst)\n",
        "\n",
        "print(array)\n",
        "print(array.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MX7Ch8CliQFH"
      },
      "source": [
        "# Numpy & Images\n",
        "Take images. Using the help of another library, PIL for example, Numpy can represent these images in array form, which can be directly used as input data in a machine learning model (provided the input dimensions match the input layer size).\n",
        "\n",
        "Try downloading an image called 'image' onto your drive (more specifically the top folder, 'My Drive') mounting your drive as described above, and making sure the image loaded correctly using the plotting libary matplotlib."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FP9XAPmPjwlO"
      },
      "source": [
        "# TODO - Mount drive to desired path\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "os.chdir('drive')\n",
        "os.chdir('My Drive')\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqd4hEmfirKt"
      },
      "source": [
        "from matplotlib import image\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# TODO - Load the image (Change extension if needed)\n",
        "image = image.imread('image.jpg')\n",
        "\n",
        "# Display the image in Colab\n",
        "# (Ensures image loaded properly)\n",
        "plt.imshow(image)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66yGdqQS2QGs"
      },
      "source": [
        "Now that the image is ready, load said image from Files using PIL, and then convert it into a numpy array and get used to how it looks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "cJvQYCZ9kPja",
        "outputId": "909e4b0b-3e61-4393-bcb7-6cafbbe714fd"
      },
      "source": [
        "from PIL import Image\n",
        "from numpy import asarray\n",
        "\n",
        "# TODO - Load the image (Change extension if needed)\n",
        "image = Image.open('image.jpg')\n",
        "\n",
        "# Convert image to numpy array\n",
        "data = asarray(image)\n",
        "\n",
        "# View Numpy array\n",
        "print(data.shape)\n",
        "print(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-19e273352966>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# TODO - Load the image (Change extension if needed)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'image.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Convert image to numpy array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2808\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2809\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2810\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'image.jpg'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ditmr-dW2uW_"
      },
      "source": [
        "# Numpy & Saving\n",
        "Now that we have created a Numpy array, we may want to save this array such that we can load it directly - rather than loading, doing pre-processing on, and then converting the image into the array again.\n",
        "\n",
        "When working with large amounts of data, this saves valuable computation time each time you train a machine learning model, since all the data pre-processing will only be done once (unless you make a mistake or want to change something)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "99KZnUz13epC",
        "outputId": "b5f5d3dc-cd82-47b6-d33e-c013a0c54215"
      },
      "source": [
        "with open('test.npy', 'wb') as f:\n",
        "    np.save(f, data)\n",
        "\n",
        "with open('test.npy', 'rb') as f:\n",
        "    data_loaded = np.load(f)\n",
        "\n",
        "data_loaded"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-92ff20f9bb8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test.npy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test.npy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdata_loaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EaUI_NcPyG-Q"
      },
      "source": [
        "Now you've had an introduction to Pandas and Numpy! We'll have more specialized data processing to come!"
      ]
    }
  ]
}